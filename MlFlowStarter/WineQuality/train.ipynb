{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK,Trials,fmin,hp,tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data_set\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data in train validation and test \n",
    "train,test = train_test_split(data,test_size=0.25,random_state=55)\n",
    "train_x = train.drop(['quality'],axis=1).values\n",
    "train_y = train['quality'].values.ravel()\n",
    "\n",
    "test_x = test.drop(['quality'],axis=1).values\n",
    "test_y = test['quality'].values.ravel()\n",
    "\n",
    "#Validation data\n",
    "train_x,val_x,train_y,val_y = train_test_split(train_x,train_y,test_size=0.20,random_state=55)\n",
    "\n",
    "signature = infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN model\n",
    "def train_model(params,epochs,train_x,train_y,val_x,val_y,test_x,test_y):\n",
    "    \n",
    "    # Define model Architecture\n",
    "    mean = np.mean(train_x,axis=0)\n",
    "    var = np.var(train_x,axis=0)\n",
    "\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean,variance=var),\n",
    "            keras.layers.Dense(64,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(optimizer = keras.optimizers.SGD(\n",
    "        learning_rate = params['lr'],\n",
    "        momentum = params['momentum']),\n",
    "        loss = 'mean_squared_error',\n",
    "        metrics = [keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    #Train the model\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(val_x,val_y),\n",
    "        epochs = 3,\n",
    "        batch_size = 64)\n",
    "\n",
    "        #Evaluate the model\n",
    "        eval_result = model.evaluate(val_x,val_y,batch_size = 64)\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        #Log the prameters\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric('Eval_rmse',eval_rmse)\n",
    "\n",
    "        #Log the model\n",
    "        mlflow.tensorflow.log_model(model,\"Model\",signature=signature)\n",
    "\n",
    "        return {'loss':eval_rmse, 'status':STATUS_OK, 'model':model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and resutls for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        val_x=val_x,\n",
    "        val_y=val_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'lr':hp.loguniform('lr',np.log(1e-5),np.log(1e-1)),\n",
    "    'momentum':hp.uniform('momentum',0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 363ms/step - loss: 33.5134 - root_mean_squared_error: 5.7891\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6024 - root_mean_squared_error: 2.5987    \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.2191 - root_mean_squared_error: 2.3258 - val_loss: 0.6255 - val_root_mean_squared_error: 0.7909\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.5601 - root_mean_squared_error: 0.7484\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5788 - root_mean_squared_error: 0.7606 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5784 - root_mean_squared_error: 0.7603 - val_loss: 0.5591 - val_root_mean_squared_error: 0.7477\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.5337 - root_mean_squared_error: 0.7305\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5325 - root_mean_squared_error: 0.7297 - val_loss: 0.5815 - val_root_mean_squared_error: 0.7626\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4895 - root_mean_squared_error: 0.6997\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5424 - root_mean_squared_error: 0.7361 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 370ms/step - loss: 33.3070 - root_mean_squared_error: 5.7712\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0130 - root_mean_squared_error: 2.6636    \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.2457 - root_mean_squared_error: 2.3284 - val_loss: 0.8067 - val_root_mean_squared_error: 0.8981\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.8287 - root_mean_squared_error: 0.9103\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8236 - root_mean_squared_error: 0.9063 - val_loss: 0.6524 - val_root_mean_squared_error: 0.8077\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4964 - root_mean_squared_error: 0.7045\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5659 - root_mean_squared_error: 0.7520 - val_loss: 0.5641 - val_root_mean_squared_error: 0.7510\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5389 - root_mean_squared_error: 0.7341\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5413 - root_mean_squared_error: 0.7355 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 361ms/step - loss: 32.6329 - root_mean_squared_error: 5.7125\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 15.1264 - root_mean_squared_error: 3.7677 - val_loss: 1.5417 - val_root_mean_squared_error: 1.2417\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.7471 - root_mean_squared_error: 1.3218\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4974 - root_mean_squared_error: 1.2234 - val_loss: 1.1253 - val_root_mean_squared_error: 1.0608\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.5345 - root_mean_squared_error: 1.2387\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2054 - root_mean_squared_error: 1.0973 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1678 - root_mean_squared_error: 1.0801 - val_loss: 0.9329 - val_root_mean_squared_error: 0.9659\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6614 - root_mean_squared_error: 0.8133\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8259 - root_mean_squared_error: 0.9067 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 365ms/step - loss: 36.7725 - root_mean_squared_error: 6.0640\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.0900 - root_mean_squared_error: 2.7261 - val_loss: 1.0227 - val_root_mean_squared_error: 1.0113\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0953 - root_mean_squared_error: 1.0466\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2307 - root_mean_squared_error: 1.1080 - val_loss: 0.7321 - val_root_mean_squared_error: 0.8556\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.1320 - root_mean_squared_error: 1.0640\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7600 - root_mean_squared_error: 0.8705 - val_loss: 0.6883 - val_root_mean_squared_error: 0.8296\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4962 - root_mean_squared_error: 0.7044\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6334 - root_mean_squared_error: 0.7950 \n",
      "\n",
      "100%|██████████| 4/4 [00:30<00:00,  7.64s/trial, best loss: 0.7510466575622559]\n",
      "Best Parameters: {'lr': np.float64(0.03500457747116137), 'momentum': np.float64(0.10661711705769816)}\n",
      "Best eval rmse: 0.7510466575622559\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    #Conduct the hyperparameters search using hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn = objective,\n",
    "        space= space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 4,\n",
    "        trials = trials\n",
    "    )\n",
    "\n",
    "    #Fetch details of the best runs\n",
    "    best_run = sorted(trials.results,key = lambda x:x['loss'])[0]\n",
    "\n",
    "    #log the best parameters\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"Eval_rmse\",best_run['loss'])\n",
    "    mlflow.tensorflow.log_model(best_run['model'],'Best model',signature=signature)\n",
    "\n",
    "\n",
    "    #Print out the best parameters and corrosponding loss\n",
    "    print(f\"Best Parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML projects\\Learning\\MLFlow\\MlFlowStarter\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1607.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.974147 ],\n",
       "       [5.7163086],\n",
       "       [5.6488905],\n",
       "       ...,\n",
       "       [6.4851284],\n",
       "       [5.4002023],\n",
       "       [5.296697 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validate the model\n",
    "\n",
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "model_uri = 'runs:/535cdf41ef1244928bd3f9a5b509dd9a/Model'\n",
    "\n",
    "# The logged model does not contain an input_example.\n",
    "# Manually generate a serving payload to verify your model prior to deployment.\n",
    "from mlflow.models import convert_input_example_to_serving_input\n",
    "\n",
    "# Define INPUT_EXAMPLE via assignment with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "serving_payload = convert_input_example_to_serving_input(test_x)\n",
    "\n",
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, serving_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Wine-quality'.\n",
      "Created version '1' of model 'Wine-quality'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1736687403018, current_stage='None', description=None, last_updated_timestamp=1736687403018, name='Wine-quality', run_id='535cdf41ef1244928bd3f9a5b509dd9a', run_link=None, source='file:///d:/ML%20projects/Learning/MLFlow/MlFlowStarter/WineQuality/mlruns/983187369760308651/535cdf41ef1244928bd3f9a5b509dd9a/artifacts/Model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Register the model\n",
    "mlflow.register_model(model_uri,\"Wine-quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
